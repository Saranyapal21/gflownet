_target_: src.gflownet.envs.base.GFlowNetEnv

# Reward function: power or boltzmann
# boltzmann: exp(-1.0 * reward_beta * proxy)
# power: (-1.0 * proxy / reward_norm) ** self.reward_beta
reward_func: boltzmann
# Beta parameter of the reward function
reward_beta: 1.0
# Reward normalization for "power" reward function
reward_norm: 1.0
# If > 0, reward_norm = reward_norm_std_mult * std(energies)
reward_norm_std_mult: 0
# Policy model (MLP) parameters
n_hid: 256
n_layers: 2
# Train set
train_set_path: None
train_set_seed: 167
ntrain: 10000
train_output: None
# Test set
test_set_path: None
test_set_base: None
test_set_seed: 167
ntest: 10000
test_output: None
# Buffer
buffer:
  replay_capacity: 10
